{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1f733e",
   "metadata": {},
   "source": [
    "## Steps to get started\n",
    "### 1) Install GraphRAG\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 2) Create Folders\n",
    "In the root folder \"GraphRAG\" create a folder \"rag\" and one inside that \"input\"\n",
    "```\n",
    "GraphRAG/\n",
    "├── rag/\n",
    "   ├── input\n",
    "```\n",
    "\n",
    "```bash command to do this\n",
    "mkdir ./rag/input\n",
    "```\n",
    "\n",
    "### 3) Download data (A Christmas Carol)\n",
    "On the command line run this\n",
    "```bash\n",
    "curl https://www.gutenberg.org/cache/epub/24022/pg24022.txt -o ./rag/input/book.txt\n",
    "```\n",
    "\n",
    "### 4) Set up your workspace\n",
    "On the command line run this\n",
    "```bash\n",
    "graphrag init --root ./rag\n",
    "```\n",
    "\n",
    "### 5) Update settings.yaml\n",
    "The previous step created a starter settings.yaml file. Overwrite/replace it with the settings.yaml file in the root folder.\n",
    "\n",
    "### 6) Setup your environment variables\n",
    "I'll give this to you but put them in the .env file\n",
    "\n",
    "### 7) Run the indexer\n",
    "On the command line run this\n",
    "``` bash\n",
    "graphrag index --root ./rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb41e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from openai import AsyncAzureOpenAI\n",
    "from typing import List, Union\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI configuration\n",
    "AZURE_ENDPOINT = \"https://transformationacademyaoa.openai.azure.com/\"\n",
    "API_VERSION = \"2024-12-01-preview\"\n",
    "DEPLOYMENT_NAME = \"text-embedding-ada-002\"\n",
    "GRAPHRAG_API_KEY = \"\"\n",
    "\n",
    "# Initialize the client\n",
    "client = AsyncAzureOpenAI(\n",
    "    api_key=GRAPHRAG_API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=AZURE_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b49f5",
   "metadata": {},
   "source": [
    "## When RAG isn't enough\n",
    "- complex multi-step reasoning\n",
    "- content in the middle is underweighted in importance\n",
    "- answering meta-questions about the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!graphrag query --root ./ragtest2 --method global --query \"What are the top themes in this story?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a8d968",
   "metadata": {},
   "source": [
    "### How to Create Retrieval-Augmented Generation (RAG) System\n",
    "- Chunking\n",
    "- Meta-data enrichment (titles, summaries, keywords)\n",
    "- Embedding\n",
    "- Indexing (Vector, Hybrid, Hierarchical)\n",
    "![Vector Similarity](./assets/vectorDbSimilarity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d04d1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_text_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Get embeddings for a given text string.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to get embeddings for\n",
    "        \n",
    "    Returns:\n",
    "        List of floats representing the embedding vector\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = await client.embeddings.create(\n",
    "            input=text,\n",
    "            model=DEPLOYMENT_NAME\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embeddings: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065b1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_score(embedding1: List[float], embedding2: List[float]) -> float: \n",
    "    \"\"\" Calculate cosine similarity between two embedding vectors using scikit-learn.\n",
    "    Args:\n",
    "    embedding1: First embedding vector (list of floats)\n",
    "    embedding2: Second embedding vector (list of floats)\n",
    "    \n",
    "Returns:\n",
    "    float: Cosine similarity score between -1 and 1\n",
    "           1 = identical vectors\n",
    "           0 = orthogonal vectors  \n",
    "           -1 = opposite vectors\n",
    "\"\"\"\n",
    "    # Convert to numpy arrays and reshape for sklearn\n",
    "    vec1 = np.array(embedding1).reshape(1, -1)\n",
    "    vec2 = np.array(embedding2).reshape(1, -1)\n",
    "\n",
    "    # Calculate cosine similarity using sklearn\n",
    "    similarity = cosine_similarity(vec1, vec2)[0][0]\n",
    "\n",
    "    return float(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out\n",
    "sample_text = \"This is a sample text for generating embeddings using Azure OpenAI.\"\n",
    "\n",
    "# Get embeddings\n",
    "embedding = await get_text_embedding(sample_text)\n",
    "\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Embedding dimension: {len(embedding)}\")\n",
    "print(f\"First 10 values: {embedding[:10]}\")\n",
    "print(f\"Data type: {type(embedding[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_text_1 = \"I am a software engineer with a passion for AI.\"\n",
    "similar_text_2 = \"I love coding and developing AI applications.\"\n",
    "opposite_text = \"I dislike programming and have no interest in AI.\"\n",
    "\n",
    "# Get embeddings for the sample texts\n",
    "embedding1 = await get_text_embedding(similar_text_1)\n",
    "embedding2 = await get_text_embedding(similar_text_2)\n",
    "opposite_embedding3 = await get_text_embedding(opposite_text)\n",
    "# Calculate cosine similarity scores\n",
    "similarity_score = cosine_similarity_score(embedding1, embedding2)\n",
    "opposite_similarity_score = cosine_similarity_score(embedding1, opposite_embedding3)    \n",
    "\n",
    "print(f\"Cosine similarity between text1 and text2: {similarity_score:.4f}\")\n",
    "print(f\"Cosine similarity between text1 and opposite_text3: {opposite_similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6ffb7",
   "metadata": {},
   "source": [
    "### How does RAG Work\n",
    "- Prompt\n",
    "- Vector Embedding\n",
    "- Similarity (Cosine, Hybrid)\n",
    "- Prompt Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb8aa1",
   "metadata": {},
   "source": [
    "### How to Create a GraphRAG System\n",
    "- Chunking\n",
    "- Entity Relationship Extraction\n",
    "- Knowledge Graph Construction: Nodes = Entities, Edges = Relationships\n",
    "- Embedding\n",
    "- Create Graph Hierarchy (Leiden Algorithm) - summaries for multiple levels of abstraction\n",
    "- Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade0c13",
   "metadata": {},
   "source": [
    "### How does GraphRAG Work\n",
    "- Prompt\n",
    "- Vector Embedding\n",
    "- Community Selection using Similarity (Cosing,Hybrid)\n",
    "- Recursive Traversal\n",
    "- Map: partial answers are generated from each selected community\n",
    "- Reduce: partial answers are ranked into a final response\n",
    "\n",
    "![Graph Hierarchy](./assets/graphRag.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
